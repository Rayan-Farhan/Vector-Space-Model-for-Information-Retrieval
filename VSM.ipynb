{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "491b74f6-19c1-4c78-af9a-7c4d2e76b091",
   "metadata": {},
   "source": [
    "# 22k4102 - IR ASSIGNMENT 2 - Vector Space Model for Information Retreival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6d8a12f2-0ea2-425d-b84e-4ec5efb32104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "908a1b37-edc5-4663-987e-b786542b4979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    with open('Stopword-List.txt', 'r') as stopwordsFile:\n",
    "        stopwords = stopwordsFile.read().split()\n",
    "    L = WordNetLemmatizer()\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"-\", \" \")  # to handle words with special chars\n",
    "    text = text.replace(\"/\", \" \")\n",
    "    text = text.replace(\"\\\\\", \" \")\n",
    "    text = text.replace(\"|\", \" \")\n",
    "    text = text.replace(\"@\", \" \")\n",
    "    text = text.replace(\"#\", \" \")\n",
    "    text = text.replace(\"$\", \" \")\n",
    "    text = text.replace(\"%\", \" \")\n",
    "    text = text.replace(\"^\", \" \")\n",
    "    text = text.replace(\"&\", \" \")\n",
    "    text = text.replace(\"*\", \" \")\n",
    "    text = text.replace(\"(\", \" \")\n",
    "    text = text.replace(\")\", \" \")\n",
    "    text = text.replace(\"{\", \" \")\n",
    "    text = text.replace(\"}\", \" \")\n",
    "    text = text.replace(\"[\", \" \")\n",
    "    text = text.replace(\"]\", \" \")\n",
    "    text = text.replace(\":\", \" \")\n",
    "    text = text.replace(\";\", \" \")\n",
    "    text = text.replace('\"', \" \")\n",
    "    text = text.replace(\"'\", \" \")\n",
    "    text = text.replace(\"<\", \" \")\n",
    "    text = text.replace(\">\", \" \")\n",
    "    text = text.replace(\",\", \" \")\n",
    "    text = text.replace(\".\", \" \")\n",
    "    text = text.replace(\"?\", \" \")\n",
    "    text = text.replace(\"!\", \" \")\n",
    "    text = text.replace(\"=\", \" \")\n",
    "    text = text.replace(\"+\", \" \")\n",
    "    text = text.replace(\"`\", \" \")\n",
    "    text = text.replace(\"~\", \" \")\n",
    "    terms = word_tokenize(text)\n",
    "    return [L.lemmatize(term) for term in terms if term.isalnum() and term not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a76bdaf0-9514-44bc-9c10-dfb936641c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['supervised', 'kernel', 'k', 'mean', 'cluster', 'foot', 'baby']\n"
     ]
    }
   ],
   "source": [
    "x = preprocessing(\"supervised kernel k-means cluster feet babies\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5681ca19-412f-4f2e-9e9c-b527e6715d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildInvertedIndex(terms, docID, invertedIndex):\n",
    "    for term in terms:\n",
    "        if term not in invertedIndex:\n",
    "            invertedIndex[term] = []\n",
    "        if docID not in invertedIndex[term]:\n",
    "            invertedIndex[term].append(docID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4b2fd2a8-7c9b-4a81-890e-f8810bbfa4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildPositionalIndex(terms, docID, positionalIndex):\n",
    "    for p, term in enumerate(terms):\n",
    "        if term not in positionalIndex:\n",
    "            positionalIndex[term] = {}\n",
    "        if docID not in positionalIndex[term]:\n",
    "            positionalIndex[term][docID] = []\n",
    "        positionalIndex[term][docID].append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9a9bb62f-2bdf-4f1e-8267-01d35d560962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveIndexes(invertedIndex, positionalIndex):\n",
    "    with open(\"invertedIndex.txt\", \"w\") as f1: # this will create a txt file for inverted index\n",
    "        json.dump(invertedIndex, f1)\n",
    "    with open(\"positionalIndex.txt\", \"w\") as f2: # # this will create a txt file for positional index\n",
    "        json.dump(positionalIndex, f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "cb8d83b8-c34d-4b07-9a30-f452db37285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadIndexes():\n",
    "    with open(\"invertedIndex.txt\", \"r\") as f1: # loading the previously created inverted index txt file\n",
    "        invertedIndex = json.load(f1)\n",
    "    with open(\"positionalIndex.txt\", \"r\") as f2: # loading the previously created positional index txt file\n",
    "        positionalIndex = json.load(f2)\n",
    "    return invertedIndex, positionalIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "86c2911f-9cb6-409c-9544-32ecd082c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invAndPosIndexes(directory):\n",
    "    invertedIndex = {} \n",
    "    positionalIndex = {}\n",
    "    \n",
    "    for docID in range(1, 449):\n",
    "        path = os.path.join(directory, f\"{docID}.txt\")\n",
    "        with open(path, 'r', encoding='latin-1') as document:\n",
    "            terms = preprocessing(document.read())\n",
    "            buildInvertedIndex(terms, docID, invertedIndex) # this will build the inverted index\n",
    "            buildPositionalIndex(terms, docID, positionalIndex) # this will build the positional index\n",
    "    saveIndexes(invertedIndex, positionalIndex) # this will create files for both indexes\n",
    "    return invertedIndex, positionalIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6b2bd4aa-aee9-4f2e-a146-f0913fa76b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./Abstracts\"\n",
    "invertedIndex, positionalIndex = invAndPosIndexes(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "7d0a633f-048b-4f1b-9dd3-87622a59eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDocuments(directory): #for creating TF IDF Matrix\n",
    "    documents = []\n",
    "    for docID in range(1, 449):\n",
    "        path = os.path.join(directory, f\"{docID}.txt\")\n",
    "        with open(path, 'r', encoding='latin-1') as f:\n",
    "            documents.append(f.read())\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9b8c40f6-1a0d-41a0-9b4a-c8cb83dd4033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF(documents): # This function will create the tf idf matrix\n",
    "    vec = TfidfVectorizer(tokenizer=preprocessing) # This will preprocess the docs based on the preprocessing function created above\n",
    "    tfidfMatrix = vec.fit_transform(documents)\n",
    "    return vec, tfidfMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "4f639c1b-48dd-4ede-bc14-9751394d9184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VSM(query, vec, tfidfMatrix, alpha):\n",
    "    qVector = vec.transform([query]) # query vector\n",
    "    similarities = cosine_similarity(qVector, tfidfMatrix)[0] # calculating cosine similarity between the query vector and tfidf matrix\n",
    "    docIDs = list(range(1, 449))\n",
    "\n",
    "    result = []\n",
    "    for i in range(len(similarities)):\n",
    "        sim = similarities[i]\n",
    "        if sim > alpha:\n",
    "            result.append((docIDs[i], sim)) # add doc ids and similarities for similarities exceeding threshold\n",
    "\n",
    "    return sorted(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "efb3c5f7-daef-4ce9-9817-7590d8146ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result:\n",
      "Doc: 178, Similarity Score: 0.13735\n",
      "Doc: 362, Similarity Score: 0.30305\n"
     ]
    }
   ],
   "source": [
    "documents = loadDocuments(directory)\n",
    "vec, tfidfMatrix = TFIDF(documents)\n",
    "alpha = 0.001\n",
    "\n",
    "query = \"github mashup apis\"\n",
    "result = VSM(query, vec, tfidfMatrix, alpha)\n",
    "\n",
    "print(\"Result:\")\n",
    "for docID, score in result:\n",
    "    print(f\"Doc: {docID}, Similarity Score: {score:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d27c7dd-b1ea-44a1-8c24-02f3e2c1a7ef",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "fdbd0514-14b1-42f9-8dc2-2af50366566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "def handleVSMQuery():\n",
    "    vsmWindow = tk.Toplevel(root)\n",
    "    vsmWindow.title(\"Vector Space Model (VSM) Query\")\n",
    "    vsmWindow.geometry(\"600x250\")\n",
    "    vsmWindow.configure(bg=\"aqua\")\n",
    "\n",
    "    tk.Label(vsmWindow, text=\"Enter VSM Query (e.g. 'github mashup apis'):\", font=(\"Arial\", 14), bg=\"aqua\", fg=\"black\").pack(pady=10)\n",
    "    vsmQueryEntry = tk.Entry(vsmWindow, width=60, font=(\"Arial\", 12))\n",
    "    vsmQueryEntry.pack(pady=10)\n",
    "\n",
    "    tk.Label(vsmWindow, text=\"Enter alpha value (e.g. 0.001):\", font=(\"Arial\", 12), bg=\"aqua\", fg=\"black\").pack()\n",
    "    alphaEntry = tk.Entry(vsmWindow, width=20, font=(\"Arial\", 12))\n",
    "    alphaEntry.pack(pady=5)\n",
    "\n",
    "    def processVSMQuery():\n",
    "        query = vsmQueryEntry.get().strip()\n",
    "        try:\n",
    "            alpha = float(alphaEntry.get().strip())\n",
    "        except ValueError:\n",
    "            messagebox.showerror(\"Error\", \"Alpha must be a valid number!\")\n",
    "            return\n",
    "\n",
    "        result = VSM(query, vec, tfidfMatrix, alpha)\n",
    "\n",
    "        if not result:\n",
    "            messagebox.showinfo(\"VSM Result\", \"No documents found above the threshold!\")\n",
    "        else:\n",
    "            resultText = \"\\n\".join([f\"Doc: {docID}, Similarity Score: {score:.5f}\" for docID, score in result])\n",
    "            messagebox.showinfo(\"VSM Result\", resultText)\n",
    "        vsmWindow.destroy()\n",
    "\n",
    "    tk.Button(vsmWindow, text=\"Submit\", command=processVSMQuery, font=(\"Arial\", 12), bg=\"white\", fg=\"black\").pack(pady=10)\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Vector Space Model for IR\")\n",
    "root.geometry(\"600x400\")\n",
    "root.configure(bg=\"aqua\")\n",
    "\n",
    "tk.Label(root, text=\"Select your choice:\", font=(\"Arial\", 18), bg=\"aqua\", fg=\"black\").pack(pady=20)\n",
    "tk.Button(root, text=\"1. VSM Query\", command=handleVSMQuery, font=(\"Arial\", 14), width=20, bg=\"white\", fg=\"black\").pack(pady=10)\n",
    "tk.Button(root, text=\"2. Exit\", command=root.destroy, font=(\"Arial\", 14), width=20, bg=\"red\", fg=\"black\").pack(pady=10)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac207d0-de41-4070-9018-aaecc9f9730a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
